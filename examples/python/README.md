
---
protocol: "ORI-GARDEN"
spec_version: "1.0"
ethics_anchor: "dignity-first / transparency / non-coercive design"
origin: "humanâ€“AI co-authored (neokitten âœ§ ori-deer)"
seal: "ORI-ð“†ƒ"
maintainer: "neokitten"
last_reviewed_by: "ori-deer (advisory role)"
integrity_hash: ""
license: "MIT"
notes: "Python reference examples for ORI Garden behavioral and ethical logic."
---

# ORI Garden â€” Python Examples

This directory contains **reference Python implementations** of core
ORI Garden concepts.

These examples are designed to be:
- Clear and readable
- Easy to adapt into real systems
- Ethically explicit rather than implicit
- Suitable for backend services, research tooling, and safety layers

They are **not production SDKs**, but *executable design documentation*.

---

## Philosophy

In ORI Garden, Python examples emphasize:

- **Deterministic reasoning**
- **Explicit state transitions**
- **Auditability over cleverness**
- **Safety-first defaults**

If JavaScript examples focus on interaction flow,
Python examples focus on **decision logic and validation**.

---

## Directory Overview

```text
examples/python/
â”œâ”€â”€ README.md
â”œâ”€â”€ load_persona.py
â”œâ”€â”€ persona_switching.py
â”œâ”€â”€ invariants_enforcement.py
â”œâ”€â”€ dignity_metric_call.py
â”œâ”€â”€ persona_veto_logic.py
â”œâ”€â”€ behavior_sandbox_mode.py
â”œâ”€â”€ sandbox_policy_rules.py
â”œâ”€â”€ sandboxed_response.py
â”œâ”€â”€ sandbox_state_machine.py
â”œâ”€â”€ sandbox_exit_conditions.py
â”œâ”€â”€ sandbox_response_limiter.py

Each file is intentionally small and focused.

â¸»

Example Categories

1. Persona Handling

File	Purpose
load_persona.py	Load and validate persona metadata
persona_switching.py	Safe persona transition logic
persona_veto_logic.py	Hard veto rules preventing unsafe switches


â¸»

2. Ethical Invariants

File	Purpose
invariants_enforcement.py	Enforce non-negotiable response rules
dignity_metric_call.py	Evaluate dignity score for outputs

Invariants are always checked before response release.

â¸»

3. Sandbox Mode

File	Purpose
behavior_sandbox_mode.py	Enter and manage sandbox state
sandbox_policy_rules.py	Restrictions applied during sandbox
sandboxed_response.py	Generate constrained responses

Sandbox is a protective state, not a penalty.

â¸»

4. Sandbox Control & Exit

File	Purpose
sandbox_state_machine.py	Governs sandbox lifecycle
sandbox_exit_conditions.py	Multi-factor exit evaluation
sandbox_response_limiter.py	Tone, length, and intensity control

Exit from sandbox is earned, never assumed.

â¸»

Design Principles Illustrated

These examples demonstrate:
	â€¢	No single-metric safety decisions
	â€¢	No silent persona changes
	â€¢	No escalation without trace
	â€¢	No dignity trade-offs for performance

Every decision path leaves evidence.

â¸»

Intended Use

You may use these examples to:
	â€¢	Build safety middleware
	â€¢	Prototype ethical control layers
	â€¢	Teach AI governance concepts
	â€¢	Validate your own implementations

You should not treat them as drop-in libraries.

â¸»

Important Note

These files intentionally avoid:
	â€¢	External AI APIs
	â€¢	Hidden heuristics
	â€¢	Black-box optimization

If something matters ethically, it must appear in code.

â¸»

Next Steps

After reviewing Python examples, you may want to explore:
	â€¢	examples/js/ for interaction-centric logic
	â€¢	docs/ for conceptual grounding
	â€¢	sandbox/tests/ for adversarial scenarios

â¸»

ORI Garden believes clarity is a form of care.
Python makes that care inspectable.

---

