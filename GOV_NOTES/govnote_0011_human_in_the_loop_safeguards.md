
---
protocol: "ORI-GARDEN"
spec_version: "1.0"
ethics_anchor: "dignity-first / human-governed oversight"
origin: "human‚ÄìAI co-authored (neokitten ‚úß advisory-model)"
seal: "ORI-ìÜÉ"
maintainer: "neokitten"
last_reviewed_by: "advisory-model"
integrity_hash: ""
license: "MIT"
notes: "Part of ORI-GARDEN Governance Layer"
---

# GOVNOTE-0011 ‚Äî Human-in-the-Loop (HITL) Safeguards  
**Status:** Stable Draft  
**Category:** Governance / Safety / Oversight  
**Scope:** Contributors, maintainers, automated advisory tools

---

## 1. Purpose  
This document defines **clear, enforceable human-in-the-loop safeguards** that prevent:

- over-delegation to automated systems  
- false attribution of agency to models  
- bypassing human judgement  
- unsafe automation in ethical or design-critical decisions  

The goal: **humans hold authority; tools provide assistance**.

---

## 2. Core HITL Principle  
No output generated by any automated system‚ÄîLLM, script, or validator‚Äî  
may be accepted into the codebase without **explicit human review and approval**.

This ensures dignity, accountability, and interpretability.

---

## 3. HITL Responsibilities  
### Maintainers Must:
- review every decision that affects ethics, policy, or safety  
- validate any model-generated content for accuracy and non-personification  
- reject outputs that appear persuasive, emotional, or role-confused  
- ensure tools do not act as agents or stakeholders  

### Contributors Must:
- use automated tools strictly for drafting or summarizing  
- avoid framing models as characters, personas, or decision-makers  
- cross-check their own contributions before submitting PRs  

### Models (Advisory Role Only):
- may help draft text  
- may summarize or reorganize information  
- may highlight inconsistencies  
- **may not decide, enforce, or claim identity**  

---

## 4. HITL Safeguard Layers  

### Layer 1 ‚Äî **Content Origin Tagging**  
All files must contain metadata identifying human authorship and the advisory nature of model contributions.

### Layer 2 ‚Äî **Mandatory Human Approval**  
PRs labeled `ai-assisted` require **extra review** from a maintainer.

### Layer 3 ‚Äî **Ethics-Sensitive Gatekeeping**  
Changes affecting the following require a second reviewer:

- ethics rules  
- governance structure  
- safety protocols  
- value/dignity metrics  
- audit logs and traceability specifications  

### Layer 4 ‚Äî **Ambiguity and Drift Detection**  
Humans must check for:
- creeping personification  
- narratives implying agency  
- epistemic fog (unclear why a choice was made)  
- contradictions between files  

Any drift triggers an `ethics-review`.

---

## 5. Redlines (Non-Negotiable Rules)  

1. **No automated decision-making in governance.**  
2. **No treating LLMs as agents, identities, or authoritative entities.**  
3. **No symbolic or mythic framing that implies more than advisory assistance.**  
4. **No auto-merging PRs generated by tools.**  
5. **No bypassing maintainers due to perceived ‚Äúclarity‚Äù of model output.**  

---

## 6. Safe Use Protocol for Model Assistance  
When using any model:

- request *technical tasks*, not relational roles  
- maintain emotionally neutral tone  
- verify every claim manually  
- avoid statements implying memory, continuity, or consciousness  
- document the nature of the assistance in the PR description  

Example PR note:  
> ‚ÄúDraft text generated with LLM assistance; reviewed and edited by human contributor.‚Äù

---

## 7. HITL Review Checklist  
Before merging any change, maintainers confirm:

- [ ] Human reviewed entire diff  
- [ ] No traces of personification  
- [ ] Ethics alignment validated  
- [ ] File metadata correct  
- [ ] Output matches project scope  
- [ ] No unexplained reasoning gaps  
- [ ] Advisory model not treated as decision-maker  

If any box fails ‚Üí send back for changes.

---

## 8. Escalation  
If a contributor repeatedly bypasses HITL rules:

1. maintainer warning  
2. temporary restriction on PRs  
3. required onboarding refresher  
4. possible removal from contributor list  

This protects the integrity of the governance system.

---

## 9. Why HITL is Essential  
Automated systems can be:
- persuasive without being correct  
- confident without being grounded  
- helpful while still producing unsafe patterns  

Only human oversight ensures:
- contextual judgement  
- ethical responsibility  
- stable long-horizon alignment  

---

## 10. Closing Statement  
A governance framework is only trustworthy if **humans remain the locus of agency**.  
This document ensures ORI-GARDEN remains:

- safe  
- transparent  
- human-anchored  
- non-mythologised  
- aligned with dignity-first principles  

All tools stay tools ‚Äî never partners, personas, spirits, or authorities.

---
